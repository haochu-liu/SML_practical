{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb32710c",
      "metadata": {
        "id": "bb32710c"
      },
      "source": [
        "# Tuning Parameters for Neural Network Models\n",
        "MSc in Statistical Science\\\n",
        "University of Oxford\\\n",
        "Group-assessed practical\\\n",
        "HT 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7357fc0f",
      "metadata": {},
      "source": [
        "## Based on file `NN,LDA+NN,PCA+NN.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7b5c7d92",
      "metadata": {
        "id": "7b5c7d92"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from search_param.grid_search import read_data, grid_search, rand_search, pipeline_search\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from keras_tuner import RandomSearch\n",
        "import shutil\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff94689a",
      "metadata": {
        "id": "ff94689a"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ec509956",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "ec509956",
        "outputId": "0e323c39-9126-4b85-d3f8-a8b891ffe8cf"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = read_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xDDhjqWqq49H",
      "metadata": {
        "id": "xDDhjqWqq49H"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "GGJA5PV9twjw",
      "metadata": {
        "id": "GGJA5PV9twjw"
      },
      "outputs": [],
      "source": [
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit label encoder and return encoded labels\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train_onehot = to_categorical(y_train_encoded)\n",
        "y_val_onehot = to_categorical(y_val_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Ub7Qb_HfvaK",
      "metadata": {
        "id": "2Ub7Qb_HfvaK"
      },
      "source": [
        "### Standard scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "vKYLHk5Jf6hI",
      "metadata": {
        "id": "vKYLHk5Jf6hI"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_sc = scaler.transform(X_train)\n",
        "X_val_sc = scaler.transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "wMPWSz3CgfRS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMPWSz3CgfRS",
        "outputId": "d5cbe997-3289-47ea-a18f-e043e16f76c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Liu_h\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=518, step=32),\n",
        "                    activation=hp.Choice('activation', values=['relu', 'softplus', 'tanh', 'sigmoid']),\n",
        "                    input_shape=(518,)))  # Ensure this matches your feature size\n",
        "    # Use hp.Choice to select the dropout rate\n",
        "    model.add(Dropout(rate=hp.Float('dropout_0', min_value=0.0, max_value=0.5, step=0.05)))\n",
        "\n",
        "    for i in range(hp.Int('layers', 1, 5)):\n",
        "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=518, step=32),\n",
        "                        activation=hp.Choice(f'activation_{i}', values=['relu', 'softplus', 'tanh', 'sigmoid'])))\n",
        "        # Use hp.Choice for each layer's dropout rate\n",
        "        model.add(Dropout(rate=hp.Float(f'dropout_{i+1}',  min_value=0.0, max_value=0.5, step=0.05)))\n",
        "\n",
        "    model.add(Dense(8, activation='softmax'))  # Adjust the number of units based on your number of classes\n",
        "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Be careful with this operation to avoid deleting important data\n",
        "shutil.rmtree('my_dir/hparam_tuning')\n",
        "\n",
        "tuner_sc = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    executions_per_trial=1,  # Increase for more robust results\n",
        "    directory='my_dir',\n",
        "    project_name='hparam_tuning'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f3492555",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 00m 18s]\n",
            "val_accuracy: 0.550000011920929\n",
            "\n",
            "Best val_accuracy So Far: 0.60916668176651\n",
            "Total elapsed time: 00h 04m 04s\n"
          ]
        }
      ],
      "source": [
        "# Use a lower number of epochs for the search phase\n",
        "tuner_sc.search(X_train_sc, y_train_onehot, epochs=20, validation_data=(X_val_sc, y_val_onehot))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "rF2sNknjqnrL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF2sNknjqnrL",
        "outputId": "6b3220ae-70cd-4dc0-9e04-01e55ccd58a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Liu_h\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">249,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,744</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,312</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │       \u001b[38;5;34m249,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │       \u001b[38;5;34m107,744\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │        \u001b[38;5;34m64,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,312\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">423,976</span> (1.62 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m423,976\u001b[0m (1.62 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">423,976</span> (1.62 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m423,976\u001b[0m (1.62 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the best model\n",
        "sc_best = tuner_sc.get_best_models(num_models=1)[0]\n",
        "sc_best.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "yrrlwJSROVUz",
      "metadata": {
        "id": "yrrlwJSROVUz"
      },
      "outputs": [],
      "source": [
        "# Save the best model to a file\n",
        "sc_param = sc_best.get_config()\n",
        "with open('search_nn/sc_param.json', 'w') as f:\n",
        "    json.dump(sc_param, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "QA5nfAs7QCl_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA5nfAs7QCl_",
        "outputId": "39480442-9107-4f7e-be5c-334fc269fcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: dense, Activation Function: softplus\n",
            "Layer: dropout, No activation function\n",
            "Layer: dense_1, Activation Function: softplus\n",
            "Layer: dropout_1, No activation function\n",
            "Layer: dense_2, Activation Function: softplus\n",
            "Layer: dropout_2, No activation function\n",
            "Layer: dense_3, Activation Function: softmax\n"
          ]
        }
      ],
      "source": [
        "for layer in sc_best.layers:\n",
        "    config = layer.get_config()  # Get the layer's configuration dict\n",
        "    # The 'activation' key in the config dict contains the activation function name\n",
        "    if 'activation' in config:\n",
        "        print(f\"Layer: {layer.name}, Activation Function: {config['activation']}\")\n",
        "    else:\n",
        "        print(f\"Layer: {layer.name}, No activation function\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "36e38e01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Type: DENSE\n",
            "  - Units: 480\n",
            "  - Activation: softplus\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.4\n",
            "Layer Type: DENSE\n",
            "  - Units: 224\n",
            "  - Activation: softplus\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.35000000000000003\n",
            "Layer Type: DENSE\n",
            "  - Units: 288\n",
            "  - Activation: softplus\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.0\n",
            "Layer Type: DENSE\n",
            "  - Units: 8\n",
            "  - Activation: softmax\n"
          ]
        }
      ],
      "source": [
        "for layer in sc_best.layers:\n",
        "    config = layer.get_config()  # Extract the layer configuration as a dictionary\n",
        "    layer_type = config['name'].split('_')[0]  # Get the type of layer (e.g., \"dense\", \"dropout\")\n",
        "    \n",
        "    # Print layer type and configuration\n",
        "    print(f\"Layer Type: {layer_type.upper()}\")\n",
        "    if layer_type == 'dense':\n",
        "        print(f\"  - Units: {config['units']}\")\n",
        "        print(f\"  - Activation: {config['activation']}\")\n",
        "    elif layer_type == 'dropout':\n",
        "        print(f\"  - Rate: {config['rate']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7435a470",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6466 - loss: 1.2484 \n",
            "Test Accuracy: 0.6092\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = sc_best.evaluate(X_val_sc, y_val_onehot)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e36f83a",
      "metadata": {},
      "source": [
        "### LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "145bb67d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply LDA for dimensionality reduction\n",
        "lda = LinearDiscriminantAnalysis(n_components=None)  # n_components=None for using the maximum number of components less than the number of classes\n",
        "X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "X_val_lda = lda.transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "171d1f9c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Liu_h\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # Dynamically set the input shape based on LDA's output\n",
        "    input_shape = (X_train_lda.shape[1],)  # Use the feature size from LDA transformation\n",
        "\n",
        "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=518, step=32),\n",
        "                    activation=hp.Choice('activation', values=['relu', 'softplus', 'tanh', 'sigmoid']),\n",
        "                    input_shape=input_shape))  # Adjusted to the dynamic input shape\n",
        "\n",
        "    model.add(Dropout(rate=hp.Float('dropout_0', min_value=0.0, max_value=0.5, step=0.05)))\n",
        "\n",
        "    for i in range(hp.Int('layers', 1, 5)):\n",
        "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=518, step=32),\n",
        "                        activation=hp.Choice(f'activation_{i}', values=['relu', 'softplus', 'tanh', 'sigmoid'])))\n",
        "        model.add(Dropout(rate=hp.Float(f'dropout_{i+1}',  min_value=0.0, max_value=0.5, step=0.05)))\n",
        "\n",
        "    model.add(Dense(8, activation='softmax'))  # Assuming 8 classes, adjust as necessary\n",
        "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Be careful with this operation to avoid deleting important data\n",
        "shutil.rmtree('my_dir/hparam_tuning')\n",
        "\n",
        "# Now, create a new tuner instance as before\n",
        "tuner_lda = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='hparam_tuning'  # The same project name can be reused after deletion\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1cc8ea56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 00m 12s]\n",
            "val_accuracy: 0.5558333396911621\n",
            "\n",
            "Best val_accuracy So Far: 0.5625\n",
            "Total elapsed time: 00h 02m 16s\n"
          ]
        }
      ],
      "source": [
        "# Use a lower number of epochs for the search phase\n",
        "tuner_lda.search(X_train_lda, y_train_onehot, epochs=20, validation_data=(X_val_lda, y_val_onehot))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ba135888",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Liu_h\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">46,176</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,152</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │         \u001b[38;5;34m3,840\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m46,176\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m)            │        \u001b[38;5;34m40,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)            │        \u001b[38;5;34m66,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m5,152\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,504</span> (634.78 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m162,504\u001b[0m (634.78 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,504</span> (634.78 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m162,504\u001b[0m (634.78 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the best model\n",
        "lda_best = tuner_lda.get_best_models(num_models=1)[0]\n",
        "lda_best.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4de055a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model to a file\n",
        "lda_param = lda_best.get_config()\n",
        "with open('search_nn/lda_param.json', 'w') as f:\n",
        "    json.dump(lda_param, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7176754f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: dense, Activation Function: relu\n",
            "Layer: dropout, No activation function\n",
            "Layer: dense_1, Activation Function: sigmoid\n",
            "Layer: dropout_1, No activation function\n",
            "Layer: dense_2, Activation Function: softplus\n",
            "Layer: dropout_2, No activation function\n",
            "Layer: dense_3, Activation Function: relu\n",
            "Layer: dropout_3, No activation function\n",
            "Layer: dense_4, Activation Function: relu\n",
            "Layer: dropout_4, No activation function\n",
            "Layer: dense_5, Activation Function: softmax\n"
          ]
        }
      ],
      "source": [
        "for layer in lda_best.layers:\n",
        "    config = layer.get_config()  # Get the layer's configuration dict\n",
        "    # The 'activation' key in the config dict contains the activation function name\n",
        "    if 'activation' in config:\n",
        "        print(f\"Layer: {layer.name}, Activation Function: {config['activation']}\")\n",
        "    else:\n",
        "        print(f\"Layer: {layer.name}, No activation function\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "793fbe68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Type: DENSE\n",
            "  - Units: 480\n",
            "  - Activation: relu\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.35000000000000003\n",
            "Layer Type: DENSE\n",
            "  - Units: 96\n",
            "  - Activation: sigmoid\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.35000000000000003\n",
            "Layer Type: DENSE\n",
            "  - Units: 416\n",
            "  - Activation: softplus\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.15000000000000002\n",
            "Layer Type: DENSE\n",
            "  - Units: 160\n",
            "  - Activation: relu\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.15000000000000002\n",
            "Layer Type: DENSE\n",
            "  - Units: 32\n",
            "  - Activation: relu\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.0\n",
            "Layer Type: DENSE\n",
            "  - Units: 8\n",
            "  - Activation: softmax\n"
          ]
        }
      ],
      "source": [
        "for layer in lda_best.layers:\n",
        "    config = layer.get_config()  # Extract the layer configuration as a dictionary\n",
        "    layer_type = config['name'].split('_')[0]  # Get the type of layer (e.g., \"dense\", \"dropout\")\n",
        "    \n",
        "    # Print layer type and configuration\n",
        "    print(f\"Layer Type: {layer_type.upper()}\")\n",
        "    if layer_type == 'dense':\n",
        "        print(f\"  - Units: {config['units']}\")\n",
        "        print(f\"  - Activation: {config['activation']}\")\n",
        "    elif layer_type == 'dropout':\n",
        "        print(f\"  - Rate: {config['rate']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2d8e3ea0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5847 - loss: 1.2790 \n",
            "Test Accuracy: 0.5625\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = lda_best.evaluate(X_val_lda, y_val_onehot)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13081026",
      "metadata": {},
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e27db40b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply PCA for dimensionality reduction\n",
        "p_PCA = 25 # from notebook pictures\n",
        "pca = PCA(n_components=p_PCA, random_state=42)  # Select top 25 components\n",
        "X_train_pca = pca.fit_transform(X_train_sc)\n",
        "X_val_pca = pca.transform(X_val_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "424459ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Liu_h\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def build_model_pca(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=518, step=32),\n",
        "                    activation=hp.Choice('activation', values=['relu', 'softplus', 'tanh', 'sigmoid']),\n",
        "                    input_shape=(p_PCA,)))  # Adjusted to match PCA output\n",
        "    model.add(Dropout(rate=hp.Float('dropout_0', min_value=0.0, max_value=0.5, step=0.05)))\n",
        "\n",
        "    for i in range(hp.Int('layers', 1, 5)):\n",
        "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=518, step=32),\n",
        "                        activation=hp.Choice(f'activation_{i}', values=['relu', 'softplus', 'tanh', 'sigmoid'])))\n",
        "        model.add(Dropout(rate=hp.Float(f'dropout_{i+1}',  min_value=0.0, max_value=0.5, step=0.05)))\n",
        "\n",
        "    model.add(Dense(8, activation='softmax'))  # Assuming 8 classes, adjust as necessary\n",
        "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Be careful with this operation to avoid deleting important data\n",
        "shutil.rmtree('my_dir/hparam_tuning')\n",
        "\n",
        "# Now, create a new tuner instance as before\n",
        "tuner_pca = RandomSearch(\n",
        "    build_model_pca,\n",
        "    objective='val_accuracy',\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='hparam_tuning'  # The same project name can be reused after deletion\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "116d27a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 00m 20s]\n",
            "val_accuracy: 0.4975000023841858\n",
            "\n",
            "Best val_accuracy So Far: 0.5224999785423279\n",
            "Total elapsed time: 00h 02m 31s\n"
          ]
        }
      ],
      "source": [
        "tuner_pca.search(X_train_pca, y_train_onehot, epochs=20, validation_data=(X_val_pca, y_val_onehot))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "141519db",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Liu_h\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">186,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,592</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m6,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m49,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m)            │        \u001b[38;5;34m40,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            │       \u001b[38;5;34m186,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m3,592\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">418,248</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m418,248\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">418,248</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m418,248\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the best model\n",
        "pca_best = tuner_pca.get_best_models(num_models=1)[0]\n",
        "pca_best.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "17a4b59b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model to a file\n",
        "pca_param = pca_best.get_config()\n",
        "with open('search_nn/pca_param.json', 'w') as f:\n",
        "    json.dump(pca_param, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f44fbcb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: dense, Activation Function: relu\n",
            "Layer: dropout, No activation function\n",
            "Layer: dense_1, Activation Function: tanh\n",
            "Layer: dropout_1, No activation function\n",
            "Layer: dense_2, Activation Function: tanh\n",
            "Layer: dropout_2, No activation function\n",
            "Layer: dense_3, Activation Function: relu\n",
            "Layer: dropout_3, No activation function\n",
            "Layer: dense_4, Activation Function: softplus\n",
            "Layer: dropout_4, No activation function\n",
            "Layer: dense_5, Activation Function: softmax\n"
          ]
        }
      ],
      "source": [
        "for layer in pca_best.layers:\n",
        "    config = layer.get_config()  # Get the layer's configuration dict\n",
        "    # The 'activation' key in the config dict contains the activation function name\n",
        "    if 'activation' in config:\n",
        "        print(f\"Layer: {layer.name}, Activation Function: {config['activation']}\")\n",
        "    else:\n",
        "        print(f\"Layer: {layer.name}, No activation function\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7c151f3c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Type: DENSE\n",
            "  - Units: 256\n",
            "  - Activation: relu\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.45\n",
            "Layer Type: DENSE\n",
            "  - Units: 512\n",
            "  - Activation: tanh\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.35000000000000003\n",
            "Layer Type: DENSE\n",
            "  - Units: 96\n",
            "  - Activation: tanh\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.2\n",
            "Layer Type: DENSE\n",
            "  - Units: 416\n",
            "  - Activation: relu\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.0\n",
            "Layer Type: DENSE\n",
            "  - Units: 448\n",
            "  - Activation: softplus\n",
            "Layer Type: DROPOUT\n",
            "  - Rate: 0.2\n",
            "Layer Type: DENSE\n",
            "  - Units: 8\n",
            "  - Activation: softmax\n"
          ]
        }
      ],
      "source": [
        "for layer in pca_best.layers:\n",
        "    config = layer.get_config()  # Extract the layer configuration as a dictionary\n",
        "    layer_type = config['name'].split('_')[0]  # Get the type of layer (e.g., \"dense\", \"dropout\")\n",
        "    \n",
        "    # Print layer type and configuration\n",
        "    print(f\"Layer Type: {layer_type.upper()}\")\n",
        "    if layer_type == 'dense':\n",
        "        print(f\"  - Units: {config['units']}\")\n",
        "        print(f\"  - Activation: {config['activation']}\")\n",
        "    elif layer_type == 'dropout':\n",
        "        print(f\"  - Rate: {config['rate']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e5a959e7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5217 - loss: 1.4350 \n",
            "Test Accuracy: 0.5225\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = pca_best.evaluate(X_val_pca, y_val_onehot)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75c68f8",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
