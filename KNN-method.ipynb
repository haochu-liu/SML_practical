{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb32710c",
   "metadata": {},
   "source": [
    "# KNN method without preprocessing (LDA and PCA)\n",
    "MSc in Statistical Science\\\n",
    "University of Oxford\\\n",
    "Group-assessed practical\\\n",
    "HT 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5c7d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.2.2.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "# The scikit-learn version is 0.15.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94689a",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec509956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data and the test inputs\n",
    "X_train = pd.read_csv('X_train.csv', index_col = 0, header=[0, 1, 2]) # inputs of the training set\n",
    "y_train = pd.read_csv('y_train.csv', index_col=0).squeeze('columns').to_numpy() # outputs of the training set\n",
    "X_test = pd.read_csv('X_test.csv', index_col = 0, header=[0, 1, 2]) # inputs of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135c1798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.266585</td>\n",
       "      <td>-0.984668</td>\n",
       "      <td>-0.729823</td>\n",
       "      <td>-0.895122</td>\n",
       "      <td>2.138628</td>\n",
       "      <td>0.935209</td>\n",
       "      <td>0.104089</td>\n",
       "      <td>-0.698659</td>\n",
       "      <td>-0.736408</td>\n",
       "      <td>-0.334376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065003</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.015776</td>\n",
       "      <td>5.743597</td>\n",
       "      <td>0.307617</td>\n",
       "      <td>0.051370</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>1.976972</td>\n",
       "      <td>0.034533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.180061</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>-0.069373</td>\n",
       "      <td>0.208734</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.577818</td>\n",
       "      <td>0.583788</td>\n",
       "      <td>0.143781</td>\n",
       "      <td>0.291556</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087692</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>64.870987</td>\n",
       "      <td>0.812988</td>\n",
       "      <td>0.082784</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>7.374503</td>\n",
       "      <td>0.074870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692900</td>\n",
       "      <td>0.356662</td>\n",
       "      <td>0.062617</td>\n",
       "      <td>0.248280</td>\n",
       "      <td>3.470037</td>\n",
       "      <td>0.166613</td>\n",
       "      <td>0.823874</td>\n",
       "      <td>0.181112</td>\n",
       "      <td>0.551939</td>\n",
       "      <td>0.357985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132387</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.023922</td>\n",
       "      <td>34.251705</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>5.927942</td>\n",
       "      <td>0.117603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243339</td>\n",
       "      <td>0.214182</td>\n",
       "      <td>-0.049026</td>\n",
       "      <td>1.456255</td>\n",
       "      <td>-0.360826</td>\n",
       "      <td>-0.875256</td>\n",
       "      <td>-0.770200</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.789956</td>\n",
       "      <td>0.448319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071478</td>\n",
       "      <td>0.019166</td>\n",
       "      <td>0.025535</td>\n",
       "      <td>1.364990</td>\n",
       "      <td>0.342285</td>\n",
       "      <td>0.081713</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100437</td>\n",
       "      <td>0.041754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.968576</td>\n",
       "      <td>0.309255</td>\n",
       "      <td>0.223164</td>\n",
       "      <td>0.160960</td>\n",
       "      <td>0.919838</td>\n",
       "      <td>-0.111985</td>\n",
       "      <td>-1.012521</td>\n",
       "      <td>-0.665692</td>\n",
       "      <td>-0.316646</td>\n",
       "      <td>-0.264381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106220</td>\n",
       "      <td>0.023536</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>3.589230</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>1.210593</td>\n",
       "      <td>0.036459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>0.503490</td>\n",
       "      <td>-0.540720</td>\n",
       "      <td>-0.690117</td>\n",
       "      <td>-0.107338</td>\n",
       "      <td>-0.647856</td>\n",
       "      <td>-0.681969</td>\n",
       "      <td>-0.246245</td>\n",
       "      <td>-0.546552</td>\n",
       "      <td>0.062783</td>\n",
       "      <td>0.070393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084929</td>\n",
       "      <td>0.017250</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>4.868783</td>\n",
       "      <td>0.668945</td>\n",
       "      <td>0.076452</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>2.045856</td>\n",
       "      <td>0.084214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>-0.600597</td>\n",
       "      <td>0.406386</td>\n",
       "      <td>-0.748409</td>\n",
       "      <td>-0.316157</td>\n",
       "      <td>-0.507428</td>\n",
       "      <td>-0.054214</td>\n",
       "      <td>-0.476804</td>\n",
       "      <td>-0.373120</td>\n",
       "      <td>-0.930158</td>\n",
       "      <td>-1.080690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075407</td>\n",
       "      <td>0.014998</td>\n",
       "      <td>0.020683</td>\n",
       "      <td>7.893681</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.561808</td>\n",
       "      <td>0.073010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>-1.014298</td>\n",
       "      <td>-0.950744</td>\n",
       "      <td>0.618304</td>\n",
       "      <td>0.204298</td>\n",
       "      <td>-0.788411</td>\n",
       "      <td>-0.794254</td>\n",
       "      <td>-0.586847</td>\n",
       "      <td>0.099172</td>\n",
       "      <td>-0.313476</td>\n",
       "      <td>-0.523417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138591</td>\n",
       "      <td>0.024969</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>27.257378</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.042598</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.778109</td>\n",
       "      <td>0.027813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>-0.002938</td>\n",
       "      <td>0.646034</td>\n",
       "      <td>-0.732819</td>\n",
       "      <td>1.205990</td>\n",
       "      <td>-0.898733</td>\n",
       "      <td>-0.684953</td>\n",
       "      <td>0.134642</td>\n",
       "      <td>-0.374792</td>\n",
       "      <td>-0.019524</td>\n",
       "      <td>-1.016032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137695</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>431.200500</td>\n",
       "      <td>0.384277</td>\n",
       "      <td>0.025731</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>10.260160</td>\n",
       "      <td>0.006870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>-0.881917</td>\n",
       "      <td>-0.615638</td>\n",
       "      <td>0.891155</td>\n",
       "      <td>4.850262</td>\n",
       "      <td>-0.349280</td>\n",
       "      <td>-1.010980</td>\n",
       "      <td>-0.577905</td>\n",
       "      <td>-0.046604</td>\n",
       "      <td>-0.828026</td>\n",
       "      <td>-0.457468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175120</td>\n",
       "      <td>0.039703</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>13.567758</td>\n",
       "      <td>0.233398</td>\n",
       "      <td>0.047689</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>2.553229</td>\n",
       "      <td>0.018049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                    \\\n",
       "statistics    kurtosis                                                     \n",
       "number              01        02        03        04        05        06   \n",
       "Id                                                                         \n",
       "0            -0.266585 -0.984668 -0.729823 -0.895122  2.138628  0.935209   \n",
       "1            -0.180061  0.260884 -0.069373  0.208734 -0.078855 -0.577818   \n",
       "2            -0.692900  0.356662  0.062617  0.248280  3.470037  0.166613   \n",
       "3             0.243339  0.214182 -0.049026  1.456255 -0.360826 -0.875256   \n",
       "4            -0.968576  0.309255  0.223164  0.160960  0.919838 -0.111985   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "5995          0.503490 -0.540720 -0.690117 -0.107338 -0.647856 -0.681969   \n",
       "5996         -0.600597  0.406386 -0.748409 -0.316157 -0.507428 -0.054214   \n",
       "5997         -1.014298 -0.950744  0.618304  0.204298 -0.788411 -0.794254   \n",
       "5998         -0.002938  0.646034 -0.732819  1.205990 -0.898733 -0.684953   \n",
       "5999         -0.881917 -0.615638  0.891155  4.850262 -0.349280 -1.010980   \n",
       "\n",
       "feature                                             ...   tonnetz            \\\n",
       "statistics                                          ...       std             \n",
       "number            07        08        09        10  ...        04        05   \n",
       "Id                                                  ...                       \n",
       "0           0.104089 -0.698659 -0.736408 -0.334376  ...  0.065003  0.016522   \n",
       "1           0.583788  0.143781  0.291556  0.007314  ...  0.087692  0.016355   \n",
       "2           0.823874  0.181112  0.551939  0.357985  ...  0.132387  0.025847   \n",
       "3          -0.770200  0.315500  0.789956  0.448319  ...  0.071478  0.019166   \n",
       "4          -1.012521 -0.665692 -0.316646 -0.264381  ...  0.106220  0.023536   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "5995       -0.246245 -0.546552  0.062783  0.070393  ...  0.084929  0.017250   \n",
       "5996       -0.476804 -0.373120 -0.930158 -1.080690  ...  0.075407  0.014998   \n",
       "5997       -0.586847  0.099172 -0.313476 -0.523417  ...  0.138591  0.024969   \n",
       "5998        0.134642 -0.374792 -0.019524 -1.016032  ...  0.137695  0.030371   \n",
       "5999       -0.577905 -0.046604 -0.828026 -0.457468  ...  0.175120  0.039703   \n",
       "\n",
       "feature                      zcr                                          \\\n",
       "statistics              kurtosis       max      mean    median       min   \n",
       "number            06          01        01        01        01        01   \n",
       "Id                                                                         \n",
       "0           0.015776    5.743597  0.307617  0.051370  0.042480  0.002441   \n",
       "1           0.016605   64.870987  0.812988  0.082784  0.069824  0.003906   \n",
       "2           0.023922   34.251705  0.850098  0.058200  0.036621  0.010254   \n",
       "3           0.025535    1.364990  0.342285  0.081713  0.075195  0.000000   \n",
       "4           0.019742    3.589230  0.322266  0.073736  0.069336  0.004395   \n",
       "...              ...         ...       ...       ...       ...       ...   \n",
       "5995        0.020335    4.868783  0.668945  0.076452  0.044434  0.001465   \n",
       "5996        0.020683    7.893681  0.584961  0.076210  0.048340  0.000000   \n",
       "5997        0.023658   27.257378  0.373047  0.042598  0.037598  0.000000   \n",
       "5998        0.029970  431.200500  0.384277  0.025731  0.025391  0.008301   \n",
       "5999        0.025094   13.567758  0.233398  0.047689  0.044922  0.015625   \n",
       "\n",
       "feature                          \n",
       "statistics       skew       std  \n",
       "number             01        01  \n",
       "Id                               \n",
       "0            1.976972  0.034533  \n",
       "1            7.374503  0.074870  \n",
       "2            5.927942  0.117603  \n",
       "3            1.100437  0.041754  \n",
       "4            1.210593  0.036459  \n",
       "...               ...       ...  \n",
       "5995         2.045856  0.084214  \n",
       "5996         2.561808  0.073010  \n",
       "5997         3.778109  0.027813  \n",
       "5998        10.260160  0.006870  \n",
       "5999         2.553229  0.018049  \n",
       "\n",
       "[6000 rows x 518 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is a 6,000 * 518 dataframe. \n",
    "# Entries (i,j) correspond to the j'th dimension of the observation i\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5cdefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Electronic', 'Rock', 'Instrumental', ..., 'Pop', 'Instrumental',\n",
       "       'Instrumental'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train contains the true class:  Electronic, Experimental, Folk, Hip-Hop, Instrumental, International, Pop or Rock\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551a7367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.974762</td>\n",
       "      <td>4.354650</td>\n",
       "      <td>3.394523</td>\n",
       "      <td>0.033462</td>\n",
       "      <td>5.611623</td>\n",
       "      <td>2.592655</td>\n",
       "      <td>3.041094</td>\n",
       "      <td>2.815378</td>\n",
       "      <td>3.954026</td>\n",
       "      <td>2.365586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052970</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>70.844788</td>\n",
       "      <td>0.671387</td>\n",
       "      <td>0.035129</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>8.394708</td>\n",
       "      <td>0.067026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033636</td>\n",
       "      <td>-0.139950</td>\n",
       "      <td>0.678688</td>\n",
       "      <td>-0.553824</td>\n",
       "      <td>-0.165293</td>\n",
       "      <td>0.370275</td>\n",
       "      <td>-0.314710</td>\n",
       "      <td>-0.368706</td>\n",
       "      <td>-0.437181</td>\n",
       "      <td>-0.441662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093105</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>18.427612</td>\n",
       "      <td>0.538574</td>\n",
       "      <td>0.055975</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.638194</td>\n",
       "      <td>0.053879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044094</td>\n",
       "      <td>4.285359</td>\n",
       "      <td>0.977213</td>\n",
       "      <td>3.240997</td>\n",
       "      <td>0.400350</td>\n",
       "      <td>1.026224</td>\n",
       "      <td>0.772464</td>\n",
       "      <td>0.807625</td>\n",
       "      <td>1.942534</td>\n",
       "      <td>1.938970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081955</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>38.401405</td>\n",
       "      <td>0.405762</td>\n",
       "      <td>0.030685</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>2.620369</td>\n",
       "      <td>0.016835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.425218</td>\n",
       "      <td>0.793007</td>\n",
       "      <td>0.509624</td>\n",
       "      <td>-0.967103</td>\n",
       "      <td>-1.432252</td>\n",
       "      <td>-0.900761</td>\n",
       "      <td>-0.501279</td>\n",
       "      <td>-0.855886</td>\n",
       "      <td>-0.556825</td>\n",
       "      <td>7.404243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098877</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.016183</td>\n",
       "      <td>4.129582</td>\n",
       "      <td>0.252441</td>\n",
       "      <td>0.037955</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.898847</td>\n",
       "      <td>0.034382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.120238</td>\n",
       "      <td>-0.503659</td>\n",
       "      <td>0.303515</td>\n",
       "      <td>-0.596549</td>\n",
       "      <td>-0.716761</td>\n",
       "      <td>-0.874363</td>\n",
       "      <td>-0.708101</td>\n",
       "      <td>-0.642351</td>\n",
       "      <td>-0.327327</td>\n",
       "      <td>-0.342220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102545</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>0.025166</td>\n",
       "      <td>16.758356</td>\n",
       "      <td>0.380371</td>\n",
       "      <td>0.027851</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.244483</td>\n",
       "      <td>0.027128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.166039</td>\n",
       "      <td>-0.660406</td>\n",
       "      <td>-0.955245</td>\n",
       "      <td>-0.689303</td>\n",
       "      <td>-0.916851</td>\n",
       "      <td>-0.136661</td>\n",
       "      <td>-0.367279</td>\n",
       "      <td>-1.135291</td>\n",
       "      <td>-1.174082</td>\n",
       "      <td>-0.609749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060857</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>8.467750</td>\n",
       "      <td>0.444824</td>\n",
       "      <td>0.055770</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>2.520271</td>\n",
       "      <td>0.056601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2.010343</td>\n",
       "      <td>0.344572</td>\n",
       "      <td>2.738141</td>\n",
       "      <td>1.238262</td>\n",
       "      <td>2.815471</td>\n",
       "      <td>0.689118</td>\n",
       "      <td>4.040531</td>\n",
       "      <td>2.749969</td>\n",
       "      <td>2.658481</td>\n",
       "      <td>4.763800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050589</td>\n",
       "      <td>0.015169</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>-0.649581</td>\n",
       "      <td>0.357422</td>\n",
       "      <td>0.126850</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234551</td>\n",
       "      <td>0.055476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.869148</td>\n",
       "      <td>-0.600280</td>\n",
       "      <td>0.105814</td>\n",
       "      <td>0.553810</td>\n",
       "      <td>-0.839182</td>\n",
       "      <td>-0.706434</td>\n",
       "      <td>-0.360566</td>\n",
       "      <td>0.053638</td>\n",
       "      <td>-0.791513</td>\n",
       "      <td>-0.669329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079556</td>\n",
       "      <td>0.025229</td>\n",
       "      <td>0.026858</td>\n",
       "      <td>1.563682</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.039138</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>1.084503</td>\n",
       "      <td>0.020284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.854251</td>\n",
       "      <td>-0.804227</td>\n",
       "      <td>1.347275</td>\n",
       "      <td>-0.748155</td>\n",
       "      <td>-0.408385</td>\n",
       "      <td>-0.909165</td>\n",
       "      <td>-0.870467</td>\n",
       "      <td>-0.077660</td>\n",
       "      <td>-0.538250</td>\n",
       "      <td>-0.108390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147899</td>\n",
       "      <td>0.023989</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>22.050222</td>\n",
       "      <td>0.319824</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.429668</td>\n",
       "      <td>0.022654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.929528</td>\n",
       "      <td>0.922116</td>\n",
       "      <td>1.074849</td>\n",
       "      <td>0.431512</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>-0.361733</td>\n",
       "      <td>0.371801</td>\n",
       "      <td>0.470401</td>\n",
       "      <td>-0.566806</td>\n",
       "      <td>0.082485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119940</td>\n",
       "      <td>0.023605</td>\n",
       "      <td>0.024036</td>\n",
       "      <td>2.444547</td>\n",
       "      <td>0.256836</td>\n",
       "      <td>0.047209</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>1.266626</td>\n",
       "      <td>0.030202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                    \\\n",
       "statistics    kurtosis                                                     \n",
       "number              01        02        03        04        05        06   \n",
       "Id                                                                         \n",
       "0             3.974762  4.354650  3.394523  0.033462  5.611623  2.592655   \n",
       "1             0.033636 -0.139950  0.678688 -0.553824 -0.165293  0.370275   \n",
       "2             0.044094  4.285359  0.977213  3.240997  0.400350  1.026224   \n",
       "3            -0.425218  0.793007  0.509624 -0.967103 -1.432252 -0.900761   \n",
       "4            -1.120238 -0.503659  0.303515 -0.596549 -0.716761 -0.874363   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "1995         -0.166039 -0.660406 -0.955245 -0.689303 -0.916851 -0.136661   \n",
       "1996          2.010343  0.344572  2.738141  1.238262  2.815471  0.689118   \n",
       "1997         -0.869148 -0.600280  0.105814  0.553810 -0.839182 -0.706434   \n",
       "1998         -0.854251 -0.804227  1.347275 -0.748155 -0.408385 -0.909165   \n",
       "1999          0.929528  0.922116  1.074849  0.431512  0.040441 -0.361733   \n",
       "\n",
       "feature                                             ...   tonnetz            \\\n",
       "statistics                                          ...       std             \n",
       "number            07        08        09        10  ...        04        05   \n",
       "Id                                                  ...                       \n",
       "0           3.041094  2.815378  3.954026  2.365586  ...  0.052970  0.013487   \n",
       "1          -0.314710 -0.368706 -0.437181 -0.441662  ...  0.093105  0.022865   \n",
       "2           0.772464  0.807625  1.942534  1.938970  ...  0.081955  0.017371   \n",
       "3          -0.501279 -0.855886 -0.556825  7.404243  ...  0.098877  0.019089   \n",
       "4          -0.708101 -0.642351 -0.327327 -0.342220  ...  0.102545  0.023823   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "1995       -0.367279 -1.135291 -1.174082 -0.609749  ...  0.060857  0.022777   \n",
       "1996        4.040531  2.749969  2.658481  4.763800  ...  0.050589  0.015169   \n",
       "1997       -0.360566  0.053638 -0.791513 -0.669329  ...  0.079556  0.025229   \n",
       "1998       -0.870467 -0.077660 -0.538250 -0.108390  ...  0.147899  0.023989   \n",
       "1999        0.371801  0.470401 -0.566806  0.082485  ...  0.119940  0.023605   \n",
       "\n",
       "feature                     zcr                                          \\\n",
       "statistics             kurtosis       max      mean    median       min   \n",
       "number            06         01        01        01        01        01   \n",
       "Id                                                                        \n",
       "0           0.022031  70.844788  0.671387  0.035129  0.026367  0.010254   \n",
       "1           0.028800  18.427612  0.538574  0.055975  0.039062  0.000000   \n",
       "2           0.016673  38.401405  0.405762  0.030685  0.028809  0.002930   \n",
       "3           0.016183   4.129582  0.252441  0.037955  0.024902  0.000000   \n",
       "4           0.025166  16.758356  0.380371  0.027851  0.019043  0.000000   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "1995        0.017722   8.467750  0.444824  0.055770  0.039062  0.001465   \n",
       "1996        0.013096  -0.649581  0.357422  0.126850  0.120117  0.000000   \n",
       "1997        0.026858   1.563682  0.152344  0.039138  0.035156  0.002441   \n",
       "1998        0.027429  22.050222  0.319824  0.032715  0.028809  0.000000   \n",
       "1999        0.024036   2.444547  0.256836  0.047209  0.041016  0.002441   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "Id                              \n",
       "0           8.394708  0.067026  \n",
       "1           3.638194  0.053879  \n",
       "2           2.620369  0.016835  \n",
       "3           1.898847  0.034382  \n",
       "4           3.244483  0.027128  \n",
       "...              ...       ...  \n",
       "1995        2.520271  0.056601  \n",
       "1996        0.234551  0.055476  \n",
       "1997        1.084503  0.020284  \n",
       "1998        3.429668  0.022654  \n",
       "1999        1.266626  0.030202  \n",
       "\n",
       "[2000 rows x 518 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test is the array of test inputs, of the same format as X_train. The objective is to predict the class (Electronic, Experimental, Folk, Hip-Hop, Instrumental, International, Pop or Rock) of the output\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c9633c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scalerx = StandardScaler()\n",
    "X_train = scalerx.fit_transform(X_train)\n",
    "X_val = scalerx.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b6f37",
   "metadata": {},
   "source": [
    "## Classification with knn and prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7884d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_all = [1,2,3, 5, 10, 20, 30, 40, 50, 75, 100,200,500,1000]\n",
    "emprisk = np.zeros(shape=len(k_all))\n",
    "emprisk2 = np.zeros(shape=len(k_all))\n",
    "for (i, k) in enumerate(k_all):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors=k) # k is the number of neighbours\n",
    "    knnclf.fit(X_train, y_train)\n",
    "    \n",
    "    emprisk[i] = 1- knnclf.score(X_train,y_train) # Return the empirical risk under the 0-1 loss\n",
    "    \n",
    "    # Show prediction rule over a range of values\n",
    "    emprisk2[i] = 1 - knnclf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8831f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of knn on the training set:  [1.         0.76604167 0.71333333 0.64104167 0.57291667 0.51395833\n",
      " 0.490625   0.48104167 0.468125   0.45333333 0.44229167 0.41479167\n",
      " 0.37854167 0.356875  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.76604167, 0.71333333, 0.64104167, 0.57291667,\n",
       "       0.51395833, 0.490625  , 0.48104167, 0.468125  , 0.45333333,\n",
       "       0.44229167, 0.41479167, 0.37854167, 0.356875  ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy of knn on the training set: ', 1- emprisk) # evaluate the accuracy on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f08911c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of knn on the testing set:  [0.42583333 0.39166667 0.3925     0.41333333 0.40916667 0.40666667\n",
      " 0.41083333 0.41583333 0.4075     0.39416667 0.38666667 0.37083333\n",
      " 0.34416667 0.3225    ]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of knn on the testing set: ', 1- emprisk2) # evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5ec2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Folk', 'Hip-Hop', 'International', ..., 'Experimental', 'Pop',\n",
       "       'Folk'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test) # compute knn predictions on the test inputs\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f3a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 6\n",
      "Best accuracy: 0.46416666666666667\n",
      "Accuracy on the validation set:  0.41583333333333333\n"
     ]
    }
   ],
   "source": [
    "# Find the best knn with parameter tuning\n",
    "\n",
    "# Define a range of k values to try\n",
    "k_values = range(1, 500, 5)\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_k = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over k values\n",
    "for k in k_values:\n",
    "    # Create a k-nearest neighbors classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Use cross-validation to evaluate the accuracy\n",
    "    accuracy_scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    \n",
    "    # Calculate the average accuracy\n",
    "    avg_accuracy = np.mean(accuracy_scores)\n",
    "    \n",
    "    # Print the average accuracy for the current k\n",
    "    #print(f'Average accuracy for k={k}: {avg_accuracy}')\n",
    "    \n",
    "    # Update the best k if the current one is better\n",
    "    if avg_accuracy > best_accuracy:\n",
    "        best_k = k\n",
    "        best_accuracy = avg_accuracy\n",
    "\n",
    "# Print the best k and corresponding accuracy\n",
    "print(f'Best k: {best_k}')\n",
    "print(f'Best accuracy: {best_accuracy}')\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "accuracy_val = best_knn_model.score(X_val, y_val)\n",
    "print(\"Accuracy on the validation set: \", accuracy_val)\n",
    "\n",
    "# Output:\n",
    "# Best k: 6\n",
    "# Best accuracy: 0.46416666666666667\n",
    "# Accuracy on the validation set:  0.41583333333333333\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0809f074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 7\n",
      "Best accuracy: 0.464375\n",
      "Accuracy on the validation set:  0.41\n"
     ]
    }
   ],
   "source": [
    "# Find the best knn with parameter tuning\n",
    "\n",
    "# Define a range of k values to try\n",
    "# search the best k in a smaller range\n",
    "k_values = range(1, 50)\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_k = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over k values\n",
    "for k in k_values:\n",
    "    # Create a k-nearest neighbors classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    #metric='cosine')\n",
    "    \n",
    "    # Use cross-validation to evaluate the accuracy\n",
    "    accuracy_scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    \n",
    "    # Calculate the average accuracy\n",
    "    avg_accuracy = np.mean(accuracy_scores)\n",
    "    \n",
    "    # Print the average accuracy for the current k\n",
    "    #print(f'Average accuracy for k={k}: {avg_accuracy}')\n",
    "    \n",
    "    # Update the best k if the current one is better\n",
    "    if avg_accuracy > best_accuracy:\n",
    "        best_k = k\n",
    "        best_accuracy = avg_accuracy\n",
    "\n",
    "# Print the best k and corresponding accuracy\n",
    "print(f'Best k: {best_k}')\n",
    "print(f'Best accuracy: {best_accuracy}')\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "accuracy_val = best_knn_model.score(X_val, y_val)\n",
    "print(\"Accuracy on the validation set: \", accuracy_val)\n",
    "\n",
    "# Output:\n",
    "# Best k: 7\n",
    "# Best accuracy: 0.464375\n",
    "# Accuracy on the validation set:  0.41\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1acb4ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Folk', 'International', 'International', ..., 'Rock', 'Pop',\n",
       "       'Hip-Hop'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = scalerx.transform(X_test)\n",
    "y_pred = best_knn_model.predict(X_test) # compute knn predictions on the test inputs\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93df0f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 7\n",
      "Best accuracy: 0.5156250000000001\n",
      "Accuracy on the validation set:  0.41\n"
     ]
    }
   ],
   "source": [
    "# Find the best knn with parameter tuning\n",
    "\n",
    "# Define a range of k values to try\n",
    "k_values = range(1, 50)\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_k = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over k values\n",
    "for k in k_values:\n",
    "    # Create a k-nearest neighbors classifier, with cosine similarity\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "    # jaccard does not work here, hamming not suitable\n",
    "    \n",
    "    # Use cross-validation to evaluate the accuracy\n",
    "    accuracy_scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    \n",
    "    # Calculate the average accuracy\n",
    "    avg_accuracy = np.mean(accuracy_scores)\n",
    "    \n",
    "    # Print the average accuracy for the current k\n",
    "    #print(f'Average accuracy for k={k}: {avg_accuracy}')\n",
    "    \n",
    "    # Update the best k if the current one is better\n",
    "    if avg_accuracy > best_accuracy:\n",
    "        best_k = k\n",
    "        best_accuracy = avg_accuracy\n",
    "\n",
    "# Print the best k and corresponding accuracy\n",
    "print(f'Best k: {best_k}')\n",
    "print(f'Best accuracy: {best_accuracy}')\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "accuracy_val = best_knn_model.score(X_val, y_val)\n",
    "print(\"Accuracy on the validation set: \", accuracy_val)\n",
    "\n",
    "# Output:\n",
    "# Best k: 7\n",
    "# Best accuracy: 0.5156250000000001\n",
    "# Accuracy on the validation set:  0.41\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61c18a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 9\n",
      "Best accuracy: 0.4866666666666667\n",
      "Accuracy on the validation set:  0.41333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Find the best knn with parameter tuning\n",
    "\n",
    "# Define a range of k values to try\n",
    "k_values = range(1, 50)\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_k = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over k values\n",
    "for k in k_values:\n",
    "    # Create a k-nearest neighbors classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='manhattan')\n",
    "    \n",
    "    # Use cross-validation to evaluate the accuracy\n",
    "    accuracy_scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    \n",
    "    # Calculate the average accuracy\n",
    "    avg_accuracy = np.mean(accuracy_scores)\n",
    "    \n",
    "    # Print the average accuracy for the current k\n",
    "    #print(f'Average accuracy for k={k}: {avg_accuracy}')\n",
    "    \n",
    "    # Update the best k if the current one is better\n",
    "    if avg_accuracy > best_accuracy:\n",
    "        best_k = k\n",
    "        best_accuracy = avg_accuracy\n",
    "\n",
    "# Print the best k and corresponding accuracy\n",
    "print(f'Best k: {best_k}')\n",
    "print(f'Best accuracy: {best_accuracy}')\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "accuracy_val = best_knn_model.score(X_val, y_val)\n",
    "print(\"Accuracy on the validation set: \", accuracy_val)\n",
    "\n",
    "# Output:\n",
    "# Best k: 9\n",
    "# Best accuracy: 0.4866666666666667\n",
    "# Accuracy on the validation set:  0.41333333333333333\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c8fe7",
   "metadata": {},
   "source": [
    "## Export in csv format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "706f456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the predictions on the test data in csv format\n",
    "prediction = pd.DataFrame(y_pred, columns=['Genre'])\n",
    "prediction.index.name='Id'\n",
    "prediction.to_csv('myprediction.csv') # export to csv file\n",
    "\n",
    "# The csv file should be of the form\n",
    "#Id, Genre\n",
    "#0, Folk\n",
    "#1, Hip-Hop\n",
    "#2, International\n",
    "#...\n",
    "#1998, Experimental\n",
    "#1999, Pop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
